#!/usr/bin/env python3
"""
Generador de Reportes de Migraci√≥n z/OS a GitHub
Analiza logs de Jenkins y genera un informe en formato Markdown
"""

import re
from pathlib import Path
from typing import Dict, List, Optional


class MigrationLogParser:
    """Parser para logs de migraci√≥n z/OS"""
    
    def __init__(self, log_path: str):
        self.log_path = Path(log_path)
        self.log_content = self._read_log()
        
    def _read_log(self) -> str:
        """Lee el contenido del archivo de log"""
        with open(self.log_path, 'r', encoding='utf-8') as f:
            return f.read()
    
    def extract_general_info(self) -> Dict[str, str]:
        """Extrae informaci√≥n general del log"""
        info = {}
        
        # Usuario
        user_match = re.search(r'Started by user (.+)', self.log_content)
        info['user'] = user_match.group(1) if user_match else 'N/A'
        
        # Repositorio
        repo_match = re.search(r'git clone https://github\.com/[^/]+/([^\s]+)\.git', self.log_content)
        info['repository'] = repo_match.group(1) if repo_match else 'N/A'
        
        # Rama principal
        branch_match = re.search(r'Already on \'([^\']+)\'', self.log_content)
        info['main_branch'] = branch_match.group(1) if branch_match else 'main'
        
        # Commit principal (primer commit de la migraci√≥n)
        commit_match = re.search(r'\[main ([a-f0-9]{7})\]', self.log_content)
        info['main_commit'] = commit_match.group(1) if commit_match else 'N/A'
        
        # Workspace
        workspace_match = re.search(r'Running on \w+ in ([^\s]+)', self.log_content)
        info['workspace'] = workspace_match.group(1) if workspace_match else 'N/A'
        
        # Estado final
        status_match = re.search(r'Finished: (\w+)', self.log_content)
        info['status'] = status_match.group(1) if status_match else 'UNKNOWN'
        
        return info
    
    def extract_environment_data(self, env_name: str) -> Dict:
        """Extrae datos de un entorno espec√≠fico (EXPLO, PREP, INTE)"""
        env_data = {
            'name': env_name,
            'programs': 0,
            'copybooks': 0,
            'dclgens': 0,
            'jcls': 0,
            'total': 0,
            'errors': 0,
            'branch': 'main' if env_name == 'EXPLO' else f'feature/migrate-{env_name.lower()}',
            'commit': None,
            'datasets': [],
            'error_details': []
        }
        
        # Buscar secci√≥n del entorno
        pattern = rf'Migraci√≥n {env_name}.*?(?=Migraci√≥n \w+|stage.*?Declarative: Post Actions|$)'
        env_section = re.search(pattern, self.log_content, re.DOTALL | re.IGNORECASE)
        
        if not env_section:
            return env_data
        
        section_text = env_section.group(0)
        
        # Extraer datasets y contar archivos
        dataset_patterns = {
            'programs': (r'({}\.\w+\.FUENTES)'.format(env_name), r'Copying {}\.\w+\.FUENTES'.format(env_name)),
            'copybooks': (r'({}\.\w+\.COBOL)'.format(env_name), r'Copying {}\.\w+\.COBOL'.format(env_name)),
            'dclgens': (r'({}\.\w+\.DCLGEN)'.format(env_name), r'Copying {}\.\w+\.DCLGEN'.format(env_name)),
            'jcls': (r'({}\.\w+\.CNTL)'.format(env_name), r'Copying {}\.\w+\.CNTL'.format(env_name))
        }
        
        for key, (dataset_pattern, copy_pattern) in dataset_patterns.items():
            # Encontrar nombre del dataset
            dataset_match = re.search(dataset_pattern, section_text)
            if dataset_match:
                env_data['datasets'].append(dataset_match.group(1))
            
            # Contar archivos copiados
            count = len(re.findall(copy_pattern, section_text))
            env_data[key] = count
        
        env_data['total'] = sum([env_data['programs'], env_data['copybooks'], 
                                  env_data['dclgens'], env_data['jcls']])
        
        # Buscar errores
        error_matches = re.findall(r'\[ERROR\].*?([A-Z0-9]+).*?(?:errno=(\d+)|ABEND)', section_text)
        env_data['errors'] = len(error_matches)
        if error_matches:
            for match in error_matches:
                env_data['error_details'].append({
                    'file': match[0],
                    'errno': match[1] if len(match) > 1 else 'N/A'
                })
        
        # Extraer commit
        commit_match = re.search(r'\[(?:main|feature/migrate-\w+) ([a-f0-9]{7})\]', section_text)
        if commit_match:
            env_data['commit'] = commit_match.group(1)
        
        return env_data
    
    def parse(self) -> Dict:
        """Parsea todo el log y retorna la informaci√≥n estructurada"""
        data = {
            'general': self.extract_general_info(),
            'environments': []
        }
        
        # Detectar entornos migrados
        env_names = re.findall(r'Migraci√≥n (\w+)', self.log_content)
        unique_envs = list(dict.fromkeys(env_names))  # Mantener orden y eliminar duplicados
        
        for env_name in unique_envs:
            env_data = self.extract_environment_data(env_name)
            data['environments'].append(env_data)
        
        return data


class MarkdownReportGenerator:
    """Generador de reportes en formato Markdown"""
    
    def __init__(self, data: Dict):
        self.data = data
        
    def generate_summary_table(self) -> str:
        """Genera la tabla de resumen ejecutivo"""
        general = self.data['general']
        env_count = len(self.data['environments'])
        env_names = ', '.join([env['name'] for env in self.data['environments']])
        
        return f"""## Resumen Ejecutivo

|  |  |
|---------|-------|
| **Estado de Ejecuci√≥n** | {general['status']} |
| **Usuario** | {general['user']} |
| **Repositorio Destino** | {general['repository']} |
| **Rama Principal** | {general['main_branch']} |
| **Entornos Migrados** | {env_count} ({env_names}) |
| **Commit Principal** | {general['main_commit']} |
| **Workspace** | {general['workspace']} |
"""
    
    def generate_volumetry_table(self) -> str:
        """Genera la tabla de volumetr√≠a general"""
        envs = self.data['environments']
        
        # Cabecera
        headers = ['| Concepto |'] + [f' {env["name"]} |' for env in envs]
        separator = ['|----------|'] + ['------|' for _ in envs]
        
        # Filas
        rows = []
        rows.append(['| **Rama Destino** |'] + [f' {env["branch"]} |' for env in envs])
        rows.append(['| **Programas COBOL** |'] + [f' {env["programs"]} |' for env in envs])
        rows.append(['| **Copybooks** |'] + [f' {env["copybooks"]} |' for env in envs])
        rows.append(['| **DCLGENs** |'] + [f' {env["dclgens"]} |' for env in envs])
        rows.append(['| **JCLs** |'] + [f' {env["jcls"]} |' for env in envs])
        rows.append(['| **Total Archivos** |'] + [f' {env["total"]} |' for env in envs])
        rows.append(['| **Errores** |'] + [f' {env["errors"]}{"*" if env["errors"] > 0 else ""} |' for env in envs])
        
        table = ''.join(headers) + '\n' + ''.join(separator) + '\n'
        for row in rows:
            table += ''.join(row) + '\n'
        
        # A√±adir nota de errores si hay alguno
        error_notes = []
        for env in envs:
            if env['errors'] > 0 and env['error_details']:
                for error in env['error_details']:
                    error_notes.append(f"Error en miembro {error['file']}: BSAM OPEN failed")
        
        if error_notes:
            table += '\n_*' + '; '.join(error_notes) + '_\n'
        
        return f"""## Volumetr√≠a General

{table}"""
    
    def generate_environment_section(self, env: Dict, index: int) -> str:
        """Genera la secci√≥n de un entorno espec√≠fico"""
        env_descriptions = {
            'EXPLO': 'Migrar el entorno de explotaci√≥n desde datasets z/OS a estructura Git.',
            'PREP': 'Migrar el entorno de preproducci√≥n a rama feature.',
            'INTE': 'Migrar el entorno de integraci√≥n a rama feature.'
        }
        
        description = env_descriptions.get(env['name'], f'Migrar el entorno {env["name"]}.')
        
        # Datasets origen
        datasets_text = ''
        if env['programs'] > 0:
            datasets_text += f"- `{env['datasets'][0] if env['datasets'] else env['name'] + '.VPROG.FUENTES'}` ‚Üí {env['programs']} programas COBOL\n"
        if env['copybooks'] > 0:
            datasets_text += f"- `{env['name']}.VCOPYS.COBOL` ‚Üí {env['copybooks']} copybooks\n"
        if env['dclgens'] > 0:
            datasets_text += f"- `{env['name']}.VCOPYS.DCLGEN` ‚Üí {env['dclgens']} DCLGENs\n"
        if env['jcls'] > 0:
            datasets_text += f"- `{env['name']}.JCL.CNTL` ‚Üí {env['jcls']} JCLs\n"
        
        # Resultado
        result_text = f"- ‚úÖ {env['total']} archivos migrados"
        if env['errors'] > 0:
            result_text += f"\n- ‚ùå {env['errors']} error"
            if env['error_details']:
                error_info = env['error_details'][0]
                result_text += f": `{error_info['file']}` (BSAM OPEN failed, errno={error_info['errno']})"
        else:
            result_text += " exitosamente"
        
        if env['commit']:
            result_text += f"\n- Commit: `{env['commit']}` - \"migracion {env['name']}\""
        
        result_text += f"\n- {'Push exitoso' if env['name'] == 'EXPLO' else 'Branch creado y pushed'} a rama `{env['branch']}`"
        
        if env['name'] != 'EXPLO':
            result_text += f"\n- PR disponible en: `/pull/new/{env['branch']}`"
        
        return f"""### {index}. Migraci√≥n {env['name']} ({'Explotaci√≥n' if env['name'] == 'EXPLO' else 'Preproducci√≥n' if env['name'] == 'PREP' else 'Integraci√≥n'})

{description}

**Datasets Origen:**
{datasets_text}
**Proceso:**
- Rama {'destino' if env['name'] == 'EXPLO' else 'creada'}: `{env['branch']}`
- {'Limpieza previa de directorios' if env['name'] != 'EXPLO' else 'Directorio destino: `/usr/lpp/IDZ/jenkins/workspace/.../esp-dvi-app-mainframe`'}
- Codificaci√≥n: IBM-1145

**Resultado:**
{result_text}
"""
    
    def generate_technical_observations(self) -> str:
        """Genera la secci√≥n de observaciones t√©cnicas"""
        # Recopilar incidencias
        incidents_text = ''
        incident_num = 1
        
        for env in self.data['environments']:
            if env['errors'] > 0 and env['error_details']:
                for error in env['error_details']:
                    incidents_text += f"{incident_num}. **Error BSAM** en archivo `{error['file']}` durante migraci√≥n {env['name']}\n"
                    incidents_text += f"   - Error code: `0x130018`\n"
                    incidents_text += f"   - Tipo: BSAM OPEN failed\n"
                    incidents_text += f"   - Impacto: 1 archivo no migrado de {env['total']} totales\n\n"
                    incident_num += 1
        
        if not incidents_text:
            incidents_text = 'No se registraron incidencias durante el proceso de migraci√≥n.\n'
        
        return f"""## Observaciones T√©cnicas

### Patrones de Nomenclatura
- Programas COBOL: `B471J*.cbl`, `VB4700*.cbl`, `VI471001.cbl`
- Copybooks: `R470JBE*.cpy`, `X*.cpy`
- DCLGENs: `T47*.cpy`
- JCLs: `X03247*.jcl`

### Incidencias
{incidents_text}"""
    
    def generate_conclusions(self) -> str:
        """Genera las conclusiones del reporte"""
        total_files = sum(env['total'] for env in self.data['environments'])
        total_errors = sum(env['errors'] for env in self.data['environments'])
        success_rate = ((total_files - total_errors) / total_files * 100) if total_files > 0 else 100
        
        env_count = len(self.data['environments'])
        feature_branches = [env['name'] for env in self.data['environments'] if env['name'] != 'EXPLO']
        
        conclusions = f"‚úÖ Migraci√≥n completada exitosamente con tasa de √©xito del **{success_rate:.1f}%**  \n"
        conclusions += f"‚úÖ {env_count} entornos migrados con estructura consistente  \n"
        
        if feature_branches:
            branches_str = ' y '.join(feature_branches)
            conclusions += f"‚úÖ Ramas feature creadas para {branches_str}  \n"
        
        conclusions += "‚úÖ Sistema de trazabilidad mediante logs configurado  \n"
        
        if total_errors > 0:
            for env in self.data['environments']:
                if env['errors'] > 0 and env['error_details']:
                    for error in env['error_details']:
                        conclusions += f"‚ö†Ô∏è 1 archivo requiere revisi√≥n manual ({error['file']})\n"
        
        return f"""## Conclusiones

{conclusions}"""
    
    def generate(self) -> str:
        """Genera el reporte completo en Markdown"""
        report = "# Reporte de Migraci√≥n z/OS a GitHub\n\n"
        report += self.generate_summary_table() + "\n"
        report += self.generate_volumetry_table() + "\n"
        report += "---\n\n## Desglose por Fase\n\n"
        
        for i, env in enumerate(self.data['environments'], 1):
            report += self.generate_environment_section(env, i)
            if i < len(self.data['environments']):
                report += "\n---\n\n"
        
        report += "\n---\n\n"
        report += self.generate_technical_observations() + "\n"
        report += "\n---\n\n"
        report += self.generate_conclusions()
        
        return report


def main():
    """Funci√≥n principal"""
    import sys
    
    if len(sys.argv) < 2:
        print("Uso: python zos_migration_report_generator.py <archivo_log> [archivo_salida]")
        sys.exit(1)
    
    log_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else "Reporte_Migracion_zOS_GitHub.md"
    
    try:
        # Parsear el log
        print(f"üìñ Analizando log: {log_file}")
        parser = MigrationLogParser(log_file)
        data = parser.parse()
        
        print(f"‚úÖ Log parseado correctamente")
        print(f"   - Entornos encontrados: {len(data['environments'])}")
        print(f"   - Usuario: {data['general']['user']}")
        print(f"   - Repositorio: {data['general']['repository']}")
        
        # Generar reporte
        print(f"\nüìù Generando reporte Markdown...")
        generator = MarkdownReportGenerator(data)
        report = generator.generate()
        
        # Guardar archivo
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"‚úÖ Reporte generado exitosamente: {output_file}")
        
    except FileNotFoundError:
        print(f"‚ùå Error: No se encontr√≥ el archivo {log_file}")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå Error inesperado: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()